---
layout: post
title: "Lessons from an HTTP Server"
---


How do we know when code is good enough? Assuming notional discipline,
a passing build is good enough for some. Perhaps a passing acceptance suite,
demonstrating that we have delivered all required features. Maybe it's unit
tests that define completion, their existence or a high percentile code
coverage metric. All these options are quantifiable, making them simple targets
to aspire to. Let us go further than that, and push for something
less tangible but more worthwhile.

At 8th Light, the HTTP Server challenge is the largest and most
complex project of the apprenticeship. One that questions this notion of "good
enough" and permits the apprentice to answer it.


### **Aim for configuration**

Pre-written Fitness acceptance tests (Cob Spec) guide the development of the
server. These tests try to ensure that the apprentice's server complies with
the HTTP/1.1 specification. Features of the HTTP specification are requested at
different end points. This makes it difficult to see if a feature should be
end point specific or generic. This sometimes leads to undesirable hard-coded
features. Projects need balance between the creation of reusable components and
their configuration.

Finding the optimal divide between specific and generic is helpful in creating
a flexible design. One method for discerning the best split is to look at the
community for help. In this case, open source servers show where a user is
expected to start configuration. Documentation explains, "this is
how you can configure the server to do what you want it to".

If only we could pair this knowledge with some foresight on the upcoming
requirements! Fortunately, our acceptance suite provides visibility on upcoming
features. Although understanding those is hard until you have a few of them
delivered. Despite this, we have all the information we need to make good
decisions on our architecture.

It is rarely possible to make the perfect architectural decision up front. As
with many things in programming, the best approach is to follow the boy scout
rule:

> Always making the code a little cleaner every time you leave it.

This ranges from refactoring to a better abstraction or giving something
a better name.


### **Naming for the domain**

> The two hardest things in programming are cache invalidation, naming things,
> and off by one errors.

Naming is always hard, so much so some people choose to [outsource
it.](http://www.bbc.co.uk/newsbeat/article/37255033/a-16-year-old-british-girl-earns-48000-helping-chinese-people-name-their-babies)

The domain of HTTP and web servers has a language convention borne out of
a necessity for clarity. We often use many words to describe the same
thing, an example is "path/route/action/URI".  All four could describe
`/foobar` in the request line `GET /foobar HTTP/1.1`. They are all appropriate,
but some could be misconstrued. "action" has connotations with just about
everything, and is only commonly used in HTML forms. URI, while valid, might
only be valid when it is specifically formatted.

As with structure, the community can also offer an insight on naming.  Server
creation has been solved many times. In doing so, so has naming that is
unambiguous and specific. Without the community, how can we improve our naming?
What can we do to check that names we assign are good enough?

The naming process is already documented in
[fantastic](http://arlobelshee.com/good-naming-is-a-process-not-a-single-step/)
blog posts, read them. We can also look at the names we give, and ask ourselves
some questions about them:

1. Is the name accurate. Does it represent the object, or describe the
behaviour well?
2. If something changed in the function or object, would the name be forced to
change?
3. Is there a more domain appropriate name for the same thing?
4. Can we shorten the name? Long names are harder to read.
5. Does anything else have a similar name, if we refactor, will we need to
   change the name based on its new use?
6. For injected objects, does the object name match its parameter name in the
function? If not, what does this tell us about the name?

This list is not exhaustive, but forms a basis for continued improvement. The
more questions we ask of our names, the more robust they become.


### **Reflect**

Lets assume that ground zero for "good enough" is a passing build, exhaustive
unit test coverage and appropriate acceptance tests. Where must we move
from there to make the real difference.

> The truest test of good enough is asking questions.

This doesn't sound revelatory. Lets ask ourselves how many times we have
moved on from a story as soon as it's delivered. Could and
should we spend more time analysing that work? Committing to this post-analysis
prepares us for the tough questions, features.  New features question our
design's structure. They result in anything from a small code addition, a bout
of refactoring or even a thorough redesign. Good software is flexible in
change.  Perfectly flexible software should not be the aim though, since
flexibility comes packaged with complexity. The aim for good enough, is to have
answers for your own questions before the feature asks them.

For naming, the exam questions are other developers, maintainers. They are the
people for whom good names are written. As with structure, our names should
answer our own questions first, before answering theirs. As craftsmen, we
take pride in our work, but even if we don't, we should all remember one thing:

> Always code as if the person who ends up maintaining your code will be
> a violent psychopath who knows where you live. Code for readability.
